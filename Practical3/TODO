TODO:
how to combine multiple classifiers using different sets of data?
use ids? hierarchy?
get pragmatic:
. weighting per class, use F1 score, change threshold
. look at each classes probability and distribution



find correlation among submitted scores to find actual values

use a better hashing function that doesn't as wide fluctuations in values, ideally an enum

can we cluster with kMeans or use PCA?

how to determine which thread metrics are yielding the best results?

how to combine model A and model B?

Classifiers
	. figure out how to make sense of kNN classifier results (returns distance to all points?)
	. try random forests
	. get Theano to work

Look into per-class error rates

Figure out what to do with send_socket / dump_line and recv_socket / dump_line

Implement optimize:
	  Try sklearn grid to optimize parameters
	  for each classifier:
	      optimize paramaters for that classifier
	      if CV set score is decreasing:
	      	 use previous parameters
		 stop optimizing

Validate Future Command Line Args:
	 . classifier parameters
	 . LOO - leave one out on/off (def: off)
       	 . store to detailed error log: fold, F1 score per class

Move this onto StarCluster

Problem statement:
skewed (aka unbalanced) multi class classification

only measured on accuracy (TP / total), not F1 score. As baseline, mark all as None and get 52% accurate.
Would be a very corrupt machine if 48% of EXEs has viruses!

The higher the accuracy, the better the score, up to 100%. Basically assume it is None unless one
of the single item classifiers reports a reasonable score.

Output is an integer 0-14 following a specific order (see Problem Description).

Classification Alternatives:

1: basic multi-class logistic regression (see warmup)

2: one class SVM

3: Exemplar SVM

4: Deep Learning / neural net / pylearn2

Challenges / Open Questions:
. how to determine confidence when classifier's output is binary? 
. should classification rates be normalized? See [1]
. vectorized output should be in YAML format for rapid reading and potential use by Theano
. maybe use AWS to do the vectorize runs (which will be slow on my machine)
. spend a little time figuring out how others have applied ML to virus detection

Background reading:

Exemplar SVM: http://www.cs.cmu.edu/~tmalisie/projects/iccv11/

Multiclass SVM classification:
  http://svmlight.joachims.org/svm_multiclass.html

Exemplar SVM on github (octave / matlab)
  https://github.com/quantombone/exemplarsvm

One against all or One against All
  http://hal.archives-ouvertes.fr/docs/00/10/39/55/PDF/cr102875872670.pdf


Classifier comparison:
  http://scikit-learn.org/stable/auto_examples/plot_classifier_comparison.html

